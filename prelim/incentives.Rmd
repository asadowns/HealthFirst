---
title: "Performance-Based HealthCare Provider Incentives"
author: "SADA Systems"
date: "January 28, 2015"
output:
  html_document:
    css: style.css
    fig_height: 10
    fig_width: 14
  word_document: default
---

##Abstract

The primary goal of this research was to explore potential Provider Compensation models for Health First.

Exploratory research was done on publicly available Medicare data as a proxy for more detailed payer, provider, and patient data. The goal was to explore the relationship between patient outcomes and perception of care, provider efficiency, and payer-provider compensation models.

We also discuss potential feature selection and modeling strategies that could build on the range of rich data sources that relate specifically to the chronic conditions Health First deals with and wishes to focus on.

This introductory research provides a framework for aggregating data sources and providing actionable insights.

Future model building would involve applying big data algorithms and machine learning to these rich, cleaned, and aggregated data sources to allow the building of very robust models for provider compensation that "price in" as many key factors as the data provided to reach the broader concepts discussed below.

We also briefly touch on other beneficial analytics opportunities we've identified as potentials for Health First.

##Data Background

The Medicare data used for this exploration is the Hospital Compare datasets. They compare quality of care at over 4,000 Medicare-certified hospitals. Much of the quality measurements are ultimately derived from NCQA data including HEDIS®.

The reports used in this report were hospital-level data for: Readmissions and Deaths, Timely and Effective Care, Hospital Value-Based Purchasing Total Performance Score (HVBP-TPS), and Payment and Value of Care.

Some of the sources of this data include:

  * General information (structural and health information technology [IT])
  * Survey of patients’ experiences (HCAHPS Survey)
  * Timely and effective care (process of care)
  * Complications (surgical complications, Agency for Healthcare Research and Quality [AHRQ] Patient Safety Indicators [PSIs], and healthcare-associated infections [HAIs])
  * Readmissions and deaths (30-day readmission and mortality )
  * Use of medical imaging (outpatient imaging efficiency)
  * Payment and value of care (Medicare spending per beneficiary [MSPB], payment for heart attack, heart failure, and pneumonia patients, and value of care for heart attack, heart failure, and pneumonia patients)

Data for payment programs includes:

  * General information (structural and health information technology [IT])
  * Hospital Value-Based Purchasing Program( HVBP)
    + HVBP Program Data and Scoring (Efficiency)
    + HVBP Program Incentive Payment Adjustments
  * Hospital-Acquired Conditions Reduction Program (HACRP)
  * Hospital Readmissions Reduction Program (HRRP)

More information on Total Performance Score can be found [here](https://www.medicare.gov/hospitalcompare/data/total-performance-scores.html).

These data sets were clean and datasets were easily aggregated based on Provider ID / Provider Number. All NA data was removed to simplify analysis. Data from 2014-2015 was used to reduce analysis scope. See Appendix 1 for data cleaning code. All data was hospital-level data.

##Exploratory Analysis of Medicare Data

```{r getdata, message=FALSE, warning=FALSE, echo=FALSE}
library(dplyr)
library(tidyr)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(knitr)
library(kfigr)
library(scales)

if (!file.exists('Hospital_Revised_Flatfiles.zip')) {
  download.file('https://data.medicare.gov/views/bg9k-emty/files/Dlx5-ywq01dGnGrU09o_Cole23nv5qWeoYaL-OzSLSU?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip','Hospital_Revised_Flatfiles.zip',method='curl')
  downloadDate <- date()  
}

if (!file.exists('raw')) {
  dir.create('raw')
  unzip('Hospital_Revised_Flatfiles.zip', exdir="./raw")
}

if (!exists('loadedData')) {
  readmissionsMortality <- tbl_df(read.csv('raw/Readmissions and Deaths - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  readmissionsMortality <- readmissionsMortality %>% select(one_of(c("Provider.ID","Measure.ID","Score"))) %>% 
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  readmissionHipKnee <- subset(readmissionsMortality, Measure.ID=='READM_30_HIP_KNEE')
  readmissionTotal <- subset(readmissionsMortality, Measure.ID=='READM_30_HOSP_WIDE')
  colnames(readmissionTotal) <- c("Provider.ID", "Measure.ID", "READM_SCORE")
  
  effectiveCare <- tbl_df(read.csv('raw/Timely and Effective Care - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))

  totalPerformanceScore <- tbl_df(read.csv('raw/hvbp_tps_10_28_2015.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  totalPerformanceScore <- totalPerformanceScore %>% 
    select(one_of(c("Provider.Number","Weighted.Patient.Experience.of.Care.Domain.Score", "Weighted.Clinical.Process.of.Care.Domain.Score","Weighted.Outcome.Domain.Score","Weighted.Efficiency.Domain.Score","Hospital.Name","Total.Performance.Score","State", "Zip.Code"))) %>% 
    na.omit() %>% 
    mutate(Provider.Number=as.character(Provider.Number))
  
  totalPerformanceScoreSectorsFlorida <- totalPerformanceScore %>%
    group_by(State) %>% 
    filter(State=='FL') %>%
    gather(domain.type,domain.score, Weighted.Patient.Experience.of.Care.Domain.Score, Weighted.Clinical.Process.of.Care.Domain.Score, Weighted.Outcome.Domain.Score, Weighted.Efficiency.Domain.Score) %>%
    transform(Hospital.Name = reorder(Hospital.Name, domain.score))

  valueOfCare <- tbl_df(read.csv('raw/Payment and Value of Care - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  valueOfCare <- valueOfCare %>% select(one_of(c("Provider.ID","Value.of.care.display.name","Value.of.care.category","Payment.category"))) %>% 
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  spendingPerPatient <- tbl_df(read.csv('raw/Medicare Hospital Spending per Patient - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  spendingPerPatient <- spendingPerPatient %>% select(one_of(c("Provider.ID","Hospital.Name","City","State","ZIP.Code","County.Name","Score"))) %>%
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  valueCareSpending <- inner_join(spendingPerPatient, valueOfCare, by="Provider.ID")
  
  readmissionSpendingScore <- inner_join(spendingPerPatient, readmissionTotal, by="Provider.ID")
  
  efficiencyScore <- totalPerformanceScoreSectorsFlorida %>% 
  arrange(Hospital.Name) %>%
  filter(domain.type=='Weighted.Efficiency.Domain.Score') %>%
  transform(Hospital.Name = reorder(Hospital.Name, domain.score))
  
  totalPerformanceReadmissionSpendingScore <- inner_join(readmissionSpendingScore, totalPerformanceScore, by=c("Provider.ID" = "Provider.Number"))
  loadedData <- TRUE
}
```

###Simple Regression Modeling

We first wanted to confirm there was a relationship between readmission rates and Medicare hospital spending per patient. We fitted a simple linear model to these two pieces of data (nationally).

```{r readmissionScoreBeneficiaryScore, echo=TRUE}
readmissionModel <- lm(Score~READM_SCORE,data=readmissionSpendingScore)
summary(readmissionModel)
```

This data is plotted below. The data and the associate P-Value confirm that there is a clear correlation between Readmissions and MSPB (Medicare Spending Per Beneficiary) score. However, the R-squared statistic,**`r round(summary(readmissionModel)$adj.r.squared,2)*100`%** shows that very little of the variance in Medicare spending per beneficiary explained by Readmissions alone. Note: The best performing hospitals are on the left of this graph since MSPB is the ratio of dollars spent by a given hospital : Average hospital. Similarly, a low readmission score means the hospital has fewer readmissions than the average hospital.

```{r readmissionScoreBeneficiaryScoreGraph, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(readmissionSpendingScore, aes(x=READM_SCORE, y=Score)) + 
  geom_point() + 
  geom_smooth(method="lm") +
  xlab("Readmission Score") +
  ylab("MSPB Score") +
  ggtitle("Medicare Spending Per Beneficiary and Readmissions")
```

We can contrast this with the Efficiency domain score as a predictor of MSPB. Which is ultimately derived from the MSPB before being weighted for variations in geographic costs and variations in patient health status. This makes it a bad predictor to use but provides some insight into what an exceptional single predictor might look like.

```{r efficiencyScoreBeneficiaryScore, echo=TRUE}
efficiencyModel <- lm(Score~Weighted.Efficiency.Domain.Score,data=totalPerformanceReadmissionSpendingScore)
summary(efficiencyModel)
```

The data is plotted below. The extremely low P-value and high R-squared, **`r round(summary(efficiencyModel)$adj.r.squared,2)*100`%**  of the variance in MSPB provides a benchmark for the amount of variance that might be readily explained with an ideal bulk metric. Here the regression line has a negative slope because an increase in efficiency correlates with a better (lower) MSPB score.

```{r efficiencyScoreBeneficiaryScoreGraph, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(totalPerformanceReadmissionSpendingScore, aes(x=Weighted.Efficiency.Domain.Score, y=Score)) + 
  geom_point() + 
  geom_smooth(method="lm") +
  xlab("Efficiency Domain Score") +
  ylab("MSPB Score") +
  ggtitle("Medicare Spending Per Beneficiary and Efficiency")
```

Interestingly, the only other factor in total provider score that provides significant predictive value of MSPB is Patient Experience of Care. This was actually a better predictor of Medicare spending per beneficiary than Readmissions. Clinical process and Outcome don't appear to have a significant effect interestingly. An analysis of variance for these models is shown below.

```{r anova, echo=FALSE}
fit1 <- lm(Score~Weighted.Patient.Experience.of.Care.Domain.Score,data=totalPerformanceReadmissionSpendingScore)
fit2 <- lm(Score~Weighted.Patient.Experience.of.Care.Domain.Score+Weighted.Outcome.Domain.Score,data=totalPerformanceReadmissionSpendingScore)
fit3 <- lm(Score~Weighted.Patient.Experience.of.Care.Domain.Score+Weighted.Outcome.Domain.Score+Weighted.Clinical.Process.of.Care.Domain.Score,data=totalPerformanceReadmissionSpendingScore)
fit4 <- lm(Score~Weighted.Patient.Experience.of.Care.Domain.Score+Weighted.Outcome.Domain.Score+Weighted.Clinical.Process.of.Care.Domain.Score+READM_SCORE,data=totalPerformanceReadmissionSpendingScore)
anova(fit1,fit2,fit3,fit4)
```

###Payment and Quality

We next wanted to explore how Medicare links payment to quality, from Medicare's documentation: 

> Hospital Value-Based Purchasing (HVBP) is part of the Centers for Medicare & Medicaid Services’ (CMS’) long-standing effort to link Medicare’s payment system to a value-based system to improve healthcare quality, including the quality of care provided in the inpatient hospital setting. The program attaches value-based purchasing to the payment system that accounts for the largest share of Medicare spending, affecting payment for inpatient stays in over 3,500 hospitals across the country. Participating hospitals are paid for inpatient acute care services based on the quality of care, not just quantity of the services they provide.

> The Total Performance Score (TPS) is comprised of the clinical process of care domain score (weighted as 10% of the TPS), the patient experience of care domain (weighted as 25% of the TPS), the outcome domain score (weighted as 40% of the TPS), and the efficiency domain score (weighted as 25% of the TPS).

More information on the TPS can be found on the medicare.gov site, [TPS](https://www.medicare.gov/hospitalcompare/data/total-performance-scores.html) and [HBVP](https://www.medicare.gov/hospitalcompare/data/hospital-vbp.html)


Below are the top 25 Florida Hospitals scored using this 4-measure, weighted system. Full hospital data is stored in variable "totalPerformanceScore". Minimum score was, **`r round(min(totalPerformanceScore$Total.Performance.Score),1)`**, maximum score was, **`r round(max(totalPerformanceScore$Total.Performance.Score),1)`**.

```{r totalPerformance, echo=FALSE, warning=FALSE}
set.seed(40)
totalPerformanceScorePlot <- totalPerformanceScoreSectorsFlorida %>% 
  arrange(Hospital.Name) %>%
  top_n(100, Hospital.Name)

ggplot(totalPerformanceScorePlot, aes(x=Hospital.Name, y=domain.score)) + 
  geom_bar(binwidth=1,aes(fill=domain.type),stat="identity") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_discrete(name = "Domain", labels = c("Experience of Care", "Clinical Process of Care", "Outcome", "Efficiency")) + 
  xlab("Hospital Name") + ylab("Total Performance Score (by domain)") + 
  ggtitle("Top 25 Florida Hospitals Total Performance Score (Weighted)")
```


```{r efficiency score, echo=FALSE, warning=FALSE}
efficiencyScorePlot <- top_n(efficiencyScore, 57, Hospital.Name)

ggplot(efficiencyScorePlot, aes(x=Hospital.Name, y=domain.score)) +
  geom_bar(binwidth=1,stat="identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("Hospital Name") + ylab("Efficiency Score") + 
  ggtitle("Florida Hospitals Efficiency Score (Score>0)")
```

##Potential Provider Compensation and Incentive Models

We examined several potential models for provider compensation and incentives. These are described below. The factors involved in these models are drawn from what we learned in the exploratory analysis and thoughts about provider decision-making.

###Basic Compensation Model

Base compensation could be linked to Overall Provider Quality (Clinical Process of Care Domain, the Patient Experience of Care domain, the Outcome domain, and the Efficiency domain). These figures could be compared to national, state, or local geographic averages. The average national provider score was **`r round(mean(totalPerformanceScore$Total.Performance.Score),1)`**. 

In order to prevent adverse selection consequences such as the best providers having the lowest rates and the highest quality of care copays/deductibles would be standardized across providers with the best providers getting to keep a larger piece of the copay and the worst providers keeping a lower percentage.

As an example, our mean hospital has a 50:50 split on all network patient copays/deductibles with the network payer. Assuming $100 copay our mean payer would be compensated $50. Other providers could be compensated according to their distance from the mean by the simple formula $Compensation = providerScore/(providerScore + meanProviderScore)$.

The worst provider in our pool would receive (out of $100):

```{r worstProvider}
copay <- 100
worst <- (min(totalPerformanceScore$Total.Performance.Score) / (mean(totalPerformanceScore$Total.Performance.Score)+min(totalPerformanceScore$Total.Performance.Score)))*copay
dollar(worst)
```

Our best provider would receive (out of $100): 

```{r bestProvider}
best <- (max(totalPerformanceScore$Total.Performance.Score) / (mean(totalPerformanceScore$Total.Performance.Score)+max(totalPerformanceScore$Total.Performance.Score)))*copay
dollar(best)
```

This system could also be easily modified to include minimum and maximum levels of compensation for providers. The base split could also be adjusted to fit real-world conditions.

More advanced versions of this model could use multiple years of historical score data to predict coming years scores.

####Variant: Tiers

A variant to the above compensation solution would be to rank hospitals by tiers (national, state, regional). This approach has the benefit that hospitals can be motivated to improve their rank by improving their score to pre/periodically-defined threshold. 

This could be as straightforward as determining the decile thresholds for the previous years performance and compensating each provider for the coming year based on which decile bucket they fall into.

```{r decileModel}
deciles <- quantile(totalPerformanceScore$Total.Performance.Score,probs=seq(0,1,0.1))
deciles
```

Using this model our worst performing providers, those with a score of `r  round(as.numeric(deciles[2]),2)` or less would receive the minimum amount from our $100 copay, perhaps $20. The best performing providers, those with a score of `r  round(as.numeric(deciles[10]),2)` or greater would keep the maximum amount from the our $100 copay, perhaps $90. The payout range could be experimentally adjusted to see what range produced the desired behavior from providers while minimizing the payout they received.

On a more granular level hospitals could be ranked and compensated according to how well they did relative to their peers in a geographic region or based on scores for specific conditions.

###Efficiency-linked Compensation Incentives

Whereas our previous model suggested a method for establishing base compensation there would ideally be a variable piece of each provider's compensation that would be linked to efficiency since this is the one element in the overall compensation model that directly effects the payer's balance sheet.

Having a variable bonus to each provider's base compensation would also provide an incentive for providers to continue to provide value.

Efficiency bonuses could be provided as Medicare does by a negative adjustment to provider's compensation or as a positive adjustment. Medicare uses readmissions for thirty days after initial treatment to determine readmissions. This methodology could be adjusted to incorporate readmissions associated with specific hospitalizations for chronic conditions and independent scores calculated for each hospital on the different chronic conditions they treated.

The formula used for readmission reduction is: 
*(Base operating DRG payment amount x readmissions adjustment factor) - base operating DRG payment amount* (DRG is Diagnosis-related groups). 

This is calculated with *readmission adjustment factor = 1 - readmission ratio* with *readmission ratio = Aggregate payments for excess readmissions/ Aggregate payments for all discharges*. 

For a positive adjustment the would be: *(Base operating DRG payment amount x readmissions adjustment ratio) + base operating DRG payment amount*.

One particular strength of this approach is that it can be done initially on a condition-by-condition basis. These conditions scores could then be aggregated to form an overall score.

####Variant: Bonus Pool

Instead of a bonus based directly on the costs of excess readmissions another option is to compensate providers who improve their efficiency by giving them a portion of a pre-determined bonus pool.

The advantage of this approach is that the overall amount of bonuses paid to providers is fixed.

In it's simplest form each provider that meets a certain minimum threshold for efficiency improvements divides the bonus pool evenly with each other provider that meets the minimum threshold for efficiency improvements.

As this formula, benefits low-performing hospitals who improve from a low base, it is probably preferable to scale the threshold so high-performing hospitals need to make smaller absolute improvements to meet the threshold. 

Another variant is to provide multiple improvement thresholds so some providers who cross multiple efficiency improvement thresholds receive multiple "shares" in the bonus pool.

###Additional Non-Financial Incentives

####Performance Profiling

Given the ease of generating real-time dashboards and reports one option to improve provider performance is to provide visibility for providers and patients into performance and efficiency of competing providers. This transparency provides clear benchmarks for providers to aim for in improving their performance.

####Technical Assistance

Payers could provide technical assistance to providers directly to help them improve their efficiency and quality of care.

This approach requires concrete, immediate costs with unknown, future benefit. Despite this using longitudinal data, randomized controlled trials, and comparisons between similar providers it might be possible to look into what technical assistance helps providers improve performance. Ultimately the payer would benefit if technical improvements could prove to improve readmissions on a cost plus basis.

Although it offers no immediate benefit and any benefits that accrue might be difficult to quantize

##Health First Data Modeling Strategies

The data analyzed so far is aggregate, derived data that already has established formulae for determining Provider Quality. Health First has access to a much wider variety of data sources:

  * HEDIS® measures for quality
  * Hospital cost and incentive data
  * Individual patient and clinician level data
  * Derived measures such as those provided by Milliman and Sherlock

This presents incredible opportunities for deriving models with superior predictive value to provide actionable insights. We would want to start by synthesizing all of the metrics available and start doing some straightforward regression modeling to determine the interplay between data features. 

Ultimately, we would want to use some kind of Boosted Random Forest which is an ideal analytic method for the data we expect with a huge number of features where the interplay between features is not going to be entirely clear. 

For instance, some HEDIS® measures, for some conditions, will have a huge impact on Provider Quality for the chronic conditions Health First wishes to treat while others may have very little. Finding these will require both intelligent feature selection done by the data analyst and domain expert along with the more advanced modeling techniques that will be used to derive the final models.

##Next Steps

The exploratory data analysis and modeling presented here provide a number of potential models for provider compensation and incentives. 

The next step would be to start working with the real-world data available. Once this data is cleaned and combined it would be possible to start creating aggregate metrics for Overall Performance and Efficiency building on what our research uncovered.

After this it would be possible to build and test several of our hypothetical models simultaneously with real payment and performance data and refine these models to maximize their utility to Health First.

##Other Potential Data Analytics Opportunities

The provider compensation analysis presented here is an example of analyzing "cold storage" data. However, we know Health First has a number of "real-time" needs for data science:

  * Matching up incoming patient data from providers with a universal patient identification number
  * Identifying patient readmission, complication, or prescription interaction risks before avoidable costs are incurred
  * Opportunities for improving provider value
  * Revenue Cycle Optimization

Each of these issues would require analysis of stored data that could be used to derive prediction algorithms that could work on incoming "streaming" data sources.

##Appendices

###Appendix 1
```{r getdataAppendix, eval=FALSE}
library(dplyr)
library(tidyr)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(knitr)
library(kfigr)
library(scales)

if (!file.exists('Hospital_Revised_Flatfiles.zip')) {
  download.file('https://data.medicare.gov/views/bg9k-emty/files/Dlx5-ywq01dGnGrU09o_Cole23nv5qWeoYaL-OzSLSU?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip','Hospital_Revised_Flatfiles.zip',method='curl')
  downloadDate <- date()  
}

if (!file.exists('raw')) {
  dir.create('raw')
  unzip('Hospital_Revised_Flatfiles.zip', exdir="./raw")
}

if (exists('loadedData')) {
  readmissionsMortality <- tbl_df(read.csv('raw/Readmissions and Deaths - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  readmissionsMortality <- readmissionsMortality %>% select(one_of(c("Provider.ID","Measure.ID","Score"))) %>% 
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  readmissionHipKnee <- subset(readmissionsMortality, Measure.ID=='READM_30_HIP_KNEE')
  readmissionTotal <- subset(readmissionsMortality, Measure.ID=='READM_30_HOSP_WIDE')
  colnames(readmissionTotal) <- c("Provider.ID", "Measure.ID", "READM_SCORE")
  
  effectiveCare <- tbl_df(read.csv('raw/Timely and Effective Care - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))

  totalPerformanceScore <- tbl_df(read.csv('raw/hvbp_tps_10_28_2015.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  totalPerformanceScore <- totalPerformanceScore %>% 
    select(one_of(c("Provider.Number","Weighted.Patient.Experience.of.Care.Domain.Score", "Weighted.Clinical.Process.of.Care.Domain.Score","Weighted.Outcome.Domain.Score","Weighted.Efficiency.Domain.Score","Hospital.Name","Total.Performance.Score","State", "Zip.Code"))) %>% 
    na.omit() %>% 
    mutate(Provider.Number=as.character(Provider.Number))
  
  totalPerformanceScoreSectorsFlorida <- totalPerformanceScore %>%
    group_by(State) %>% 
    filter(State=='FL') %>%
    gather(domain.type,domain.score, Weighted.Patient.Experience.of.Care.Domain.Score, Weighted.Clinical.Process.of.Care.Domain.Score, Weighted.Outcome.Domain.Score, Weighted.Efficiency.Domain.Score) %>%
    transform(Hospital.Name = reorder(Hospital.Name, domain.score))

  valueOfCare <- tbl_df(read.csv('raw/Payment and Value of Care - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  valueOfCare <- valueOfCare %>% select(one_of(c("Provider.ID","Value.of.care.display.name","Value.of.care.category","Payment.category"))) %>% 
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  spendingPerPatient <- tbl_df(read.csv('raw/Medicare Hospital Spending per Patient - Hospital.csv', stringsAsFactors = FALSE, header = TRUE, na.strings=c("Not Available","Too Few To Report")))
  spendingPerPatient <- spendingPerPatient %>% select(one_of(c("Provider.ID","Hospital.Name","City","State","ZIP.Code","County.Name","Score"))) %>%
    na.omit() %>% mutate(Provider.ID=as.character(Provider.ID))
  
  valueCareSpending <- inner_join(spendingPerPatient, valueOfCare, by="Provider.ID")
  
  readmissionSpendingScore <- inner_join(spendingPerPatient, readmissionTotal, by="Provider.ID")
  
  efficiencyScore <- totalPerformanceScoreSectorsFlorida %>% 
  arrange(Hospital.Name) %>%
  filter(domain.type=='Weighted.Efficiency.Domain.Score') %>%
  transform(Hospital.Name = reorder(Hospital.Name, domain.score))
  
  totalPerformanceReadmissionSpendingScore <- inner_join(readmissionSpendingScore, totalPerformanceScore, by=c("Provider.ID" = "Provider.Number"))
  loadedData <- TRUE
}
```

###Appendix 2

[Source](https://www.cms.gov/Medicare/Medicare-fee-for-service-payment/acuteinpatientpps/readmissions-reduction-program.html)

####Formulas to Calculate the Readmission Adjustment Factor

Excess readmission ratio = risk-adjusted predicted readmissions/risk-adjusted expected readmissions

Aggregate payments for excess readmissions = [sum of base operating DRG payments for AMI x (excess readmission ratio for AMI-1)] + [sum of base operating DRG payments for HF x (excess readmission ratio for HF-1)] + [sum of base operating DRG payments for PN x (excess readmission ratio for PN-1)] + [sum of base operating DRG payments for COPD x (excess readmission ratio for COPD-1)] + [sum of base operating payments for THA/TKA x (excess readmission ratio for THA/TKA -1)]

*Note, if a hospital’s excess readmission ratio for a condition is less than/equal to 1, then there are no aggregate payments for excess readmissions for that condition included in this calculation.

Aggregate payments for all discharges = sum of base operating DRG payments for all discharges

Ratio = 1 - (Aggregate payments for excess readmissions/ Aggregate payments for all discharges)

Readmissions Adjustment Factor = the higher of the Ratio or 0.97 (3% reduction). 
(For FY 2013, the higher of the Ratio or 0.99% (1% reduction), and for FY 2014, the higher of the Ratio or 0.98% (2% reduction).)

####Formulas to Compute the Readmission Payment Adjustment Amount

Wage-adjusted DRG operating amount* = DRG weight x [(labor share x wage index) + (non-labor share x cola, if applicable)]

*Note, If the case is subject to the transfer policy, then this amount includes an applicable payment adjustment for transfers under § 412.4(f).

Base Operating DRG Payment Amount = Wage-adjusted DRG operating amount + new technology payment, if applicable.

Readmissions Payment Adjustment Amount = [Base operating DRG payment amount x readmissions adjustment factor] - base operating DRG payment amount.

*The readmissions adjustment factor is always less than 1.0000, therefore, the readmissions payment adjustment amount will always be a negative amount (i.e., a payment reduction).

